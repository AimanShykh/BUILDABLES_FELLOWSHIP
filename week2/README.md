# Week 2 ‚Äì Conversational LLMs & System Prompts

This week focused on **Conversational LLMs** and how they are used to build intelligent, context-aware chatbots. The learning included understanding **LLM APIs**, the role of **system prompts**, and how conversations are maintained in different applications.

---

## üìñ Topics Covered

* **Conversational LLMs**
  

* **APIs for LLMs**

  * How developers interact with models via APIs
  * Request-response cycles with `messages` (system, user, assistant roles)
  * Differences between Completion APIs and Chat APIs

* **System Prompts**

  * Defining the role, behavior, or style of the chatbot
  * Example: formal assistant, casual buddy, teacher, etc.
  * Importance of prompt engineering for shaping responses

---

## üõ†Ô∏è Project ‚Äì Conversational Chatbots (CLI + Web)

For this week‚Äôs project, I built two versions of a chatbot powered by LLMs:

1. **Basic CLI Chatbot**

   * A terminal-based chatbot that works in a continuous chat loop
   * Maintains conversation history for context
   

2. **Streamlit Web Chatbot**

   * A web-based chatbot built with Streamlit
   * Users can **choose different system prompts** (e.g., friendly, professional, or instructive assistant)
   * Showcases how prompts can shape chatbot behavior
 

**Tech Stack:**

* Python
* Gemini API 
* Streamlit (for web interface)

---



